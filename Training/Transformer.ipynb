{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merge_train.csv',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['weekdays'] = df['date'].dt.dayofweek  # 1 for weekend, 0 for weekday\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "# df['EMA_4h'] = df['Price'].ewm(span=48, adjust=False).mean()\n",
    "\n",
    "\n",
    "df['SMA_4h'] = df['Price'].shift(1).rolling(window=48).mean()\n",
    "# df['EMA_1d'] = df['Price'].ewm(span=288, adjust=False).mean()\n",
    "df['Forecast_difference_0.5 hour future'] = df['Forecast_Roof_0.5 hour future'] - df['Forecast_Demand_0.5 hour future']\n",
    "df[\"Forecast_ratio_0.5 hour future\"] = df['Forecast_Roof_0.5 hour future'] / df['Forecast_Demand_0.5 hour future']\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['Region', 'Actual_Roof_OPOWER', 'Actual_Roof_LASTCHANGED'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "\n",
    "def create_qld_holidays_list():\n",
    "    holidays = [\n",
    "        # 2023\n",
    "        \"2023-01-01\", \"2023-01-02\", \"2023-01-26\", \"2023-04-07\", \"2023-04-08\", \"2023-04-09\", \"2023-04-10\",\n",
    "        \"2023-04-25\", \"2023-05-01\", \"2023-08-16\", \"2023-10-02\", \"2023-12-25\", \"2023-12-26\",\n",
    "        # 2024\n",
    "        \"2024-01-01\", \"2024-01-26\", \"2024-03-29\", \"2024-03-30\", \"2024-03-31\", \"2024-04-01\",\n",
    "        \"2024-04-25\", \"2024-05-06\", \"2024-08-14\", \"2024-10-07\", \"2024-12-25\", \"2024-12-26\",\n",
    "        # 2025\n",
    "        \"2025-01-01\", \"2025-01-27\", \"2025-04-18\", \"2025-04-19\", \"2025-04-20\", \"2025-04-21\",\n",
    "        \"2025-04-25\", \"2025-05-05\", \"2025-08-13\", \"2025-10-06\", \"2025-12-25\", \"2025-12-26\"\n",
    "    ]\n",
    "    return pd.to_datetime(holidays)\n",
    "\n",
    "def add_qld_holidays(df):\n",
    "    holidays = create_qld_holidays_list()\n",
    "    \n",
    "   \n",
    "    df['is_holiday'] = 0\n",
    "    \n",
    "    df.loc[df.index.isin(holidays), 'is_holiday'] = 1\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_qld_holidays(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"time_idx\"] = np.arange(len(df))\n",
    "X = df.drop('Price', axis=1)\n",
    "\n",
    "y = df['Price']\n",
    "\n",
    "\n",
    "train_end_date = pd.to_datetime(\"2024-04-30 23:59:59\")\n",
    "val_end_date = pd.to_datetime(\"2024-05-31 23:59:59\")\n",
    "test_start_date = pd.to_datetime(\"2024-06-01 00:00:00\")\n",
    "\n",
    "\n",
    "X_train = X[X.index <= train_end_date]\n",
    "X_val = X[(X.index > train_end_date) & (X.index <= val_end_date)]\n",
    "X_test = X[X.index >= test_start_date]\n",
    "\n",
    "y_train = y[y.index <= train_end_date]\n",
    "y_val = y[(y.index > train_end_date) & (y.index <= val_end_date)]\n",
    "y_test = y[y.index >= test_start_date]\n",
    "\n",
    "# train_time_idx = torch.tensor(X_train[\"time_idx\"].values, dtype=torch.float32)\n",
    "# val_time_idx = torch.tensor(X_val[\"time_idx\"].values, dtype=torch.float32)\n",
    "# test_time_idx = torch.tensor(X_test[\"time_idx\"].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Demand', 'Price', 'Forecast_Demand_0.5 hour future',\n",
       "       'Forecast_Demand_1 hour future', 'Forecast_Demand_1.5 hours future',\n",
       "       'Forecast_Demand_2 hours future', 'Forecast_Demand_2.5 hours future',\n",
       "       'Forecast_Demand_3 hours future', 'Forecast_Demand_3.5 hours future',\n",
       "       'Forecast_Demand_4 hours future', 'Forecast_Demand_4.5 hours future',\n",
       "       'Forecast_Demand_5 hours future', 'Forecast_Demand_5.5 hours future',\n",
       "       'Forecast_Demand_6 hours future', 'Forecast_Demand_6.5 hours future',\n",
       "       'Forecast_Demand_7 hours future', 'Forecast_Demand_7.5 hours future',\n",
       "       'Forecast_Demand_8 hours future', 'Forecast_Demand_8.5 hours future',\n",
       "       'Forecast_Demand_9 hours future', 'Forecast_Demand_9.5 hours future',\n",
       "       'Forecast_Roof_0.5 hour future', 'Forecast_Roof_1 hour future',\n",
       "       'Forecast_Roof_1.5 hours future', 'Forecast_Roof_2 hours future',\n",
       "       'Forecast_Roof_2.5 hours future', 'Forecast_Roof_3 hours future',\n",
       "       'Forecast_Roof_3.5 hours future', 'Forecast_Roof_4 hours future',\n",
       "       'Forecast_Roof_4.5 hours future', 'Forecast_Roof_5 hours future',\n",
       "       'Forecast_Roof_5.5 hours future', 'Forecast_Roof_6 hours future',\n",
       "       'Forecast_Roof_6.5 hours future', 'Forecast_Roof_7 hours future',\n",
       "       'Forecast_Roof_7.5 hours future', 'Forecast_Roof_8 hours future',\n",
       "       'Forecast_Roof_8.5 hours future', 'Forecast_Roof_9 hours future',\n",
       "       'Forecast_Roof_9.5 hours future', 'Actual_Demand_OPERATIONAL_DEMAND',\n",
       "       'Adjusted_Actual_Roof_OPOWER', 'month', 'day', 'weekdays', 'hour',\n",
       "       'minute', 'SMA_4h', 'Forecast_difference_0.5 hour future',\n",
       "       'Forecast_ratio_0.5 hour future', 'is_holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "\n",
    "\n",
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=24,  \n",
    "    context_length=48,  \n",
    "    num_time_features=X_train.shape[1],  \n",
    "    num_static_categorical_features=0,  \n",
    "    num_static_real_features=0, \n",
    "    embedding_dimension=16 \n",
    ")\n",
    "\n",
    "\n",
    "model = TimeSeriesTransformerModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (48) must match the size of tensor b (81504) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m past_observed_mask \u001b[38;5;241m=\u001b[39m past_observed_mask_train\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 模型前向傳播\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m predicted_values \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_values\u001b[38;5;241m.\u001b[39mshape)  \n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1269\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1267\u001b[0m context \u001b[38;5;241m=\u001b[39m past_values[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length :]\n\u001b[0;32m   1268\u001b[0m observed_context \u001b[38;5;241m=\u001b[39m past_observed_mask[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length :]\n\u001b[1;32m-> 1269\u001b[0m _, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1271\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1272\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mcat((past_values, future_values), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (past_values \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m   1275\u001b[0m )\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# static features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:145\u001b[0m, in \u001b[0;36mTimeSeriesMeanScaler.forward\u001b[1;34m(self, data, observed_indicator)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m, data: torch\u001b[38;5;241m.\u001b[39mTensor, observed_indicator: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[0;32m    133\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        data (`torch.Tensor` of shape `(batch_size, sequence_length, num_input_channels)`):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m            `(batch_size, 1, num_input_channels)`)\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     ts_sum \u001b[38;5;241m=\u001b[39m (\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobserved_indicator\u001b[49m)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    146\u001b[0m     num_observed \u001b[38;5;241m=\u001b[39m observed_indicator\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    148\u001b[0m     scale \u001b[38;5;241m=\u001b[39m ts_sum \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(num_observed, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (48) must match the size of tensor b (81504) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "past_observed_mask_train = torch.ones_like(X_train, dtype=torch.bool)\n",
    "past_observed_mask_val = torch.ones_like(X_val, dtype=torch.bool)\n",
    "past_observed_mask_test = torch.ones_like(X_test, dtype=torch.bool)\n",
    "\n",
    "past_values = X_train.unsqueeze(0)\n",
    "past_time_features = train_time_idx.unsqueeze(0).unsqueeze(1).unsqueeze(-1)\n",
    "past_observed_mask = past_observed_mask_train.unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "# 模型前向傳播\n",
    "output = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask\n",
    ")\n",
    "\n",
    "\n",
    "predicted_values = output.last_hidden_state\n",
    "\n",
    "print(predicted_values.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_values shape: torch.Size([1, 81504, 51])\n",
      "past_time_features shape: torch.Size([1, 1, 81504, 1])\n",
      "past_observed_mask shape: torch.Size([1, 1, 81504, 51])\n"
     ]
    }
   ],
   "source": [
    "# 查看數據形狀\n",
    "print(f\"past_values shape: {past_values.shape}\")\n",
    "print(f\"past_time_features shape: {past_time_features.shape}\")\n",
    "print(f\"past_observed_mask shape: {past_observed_mask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TimeSeries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
